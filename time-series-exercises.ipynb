{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the code from the lesson as a guide, create a dataframe named items that has all of the data for items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_page: 3\n",
      "next_page: /api/v1/items?page=2\n"
     ]
    }
   ],
   "source": [
    "# variable holds python object that represents an HTTP response from the given url\n",
    "response = requests.get('https://python.zach.lol/api/v1/items')\n",
    "\n",
    "# save contents of response in format we can access more easily\n",
    "data = response.json()\n",
    "\n",
    "# save data from items section of data\n",
    "items = pd.DataFrame(data['payload']['items'])\n",
    "\n",
    "# print max pages and next page so we know how many pages there are and what the next page is\n",
    "print('max_page: %s' % data['payload']['max_page'])\n",
    "print('next_page: %s' % data['payload']['next_page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_page: 3\n",
      "next_page: /api/v1/items?page=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40, 6)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save url without page specifications\n",
    "base_url = 'https://python.zach.lol'\n",
    "\n",
    "# save requests.get function that uses url above concatenated with string\n",
    "# end result is new url that gets data from next page being passed to requests.get function\n",
    "response = requests.get(base_url + data['payload']['next_page'])\n",
    "\n",
    "# save retrieved data\n",
    "data = response.json()\n",
    "\n",
    "# print max pages and next page so we know how many pages there are and what the next page is\n",
    "print('max_page: %s' % data['payload']['max_page'])\n",
    "print('next_page: %s' % data['payload']['next_page'])\n",
    "\n",
    "# concat new dataframe with old dataframe and drop index\n",
    "items = pd.concat([items, pd.DataFrame(data['payload']['items'])]).reset_index(drop = True)\n",
    "\n",
    "# check shape to ensure new DF is growing correctly\n",
    "items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_page: 3\n",
      "next_page: None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat next page url info with base url and pass to requests.get function\n",
    "response = requests.get(base_url + data['payload']['next_page'])\n",
    "\n",
    "# save data in json format\n",
    "data = response.json()\n",
    "\n",
    "# print max and next page info\n",
    "print('max_page: %s' % data['payload']['max_page'])\n",
    "print('next_page: %s' % data['payload']['next_page'])\n",
    "\n",
    "# concat new df to old df and drop index\n",
    "items = pd.concat([items, pd.DataFrame(data['payload']['items'])]).reset_index(drop=True)\n",
    "\n",
    "# check shape to ensure new DF is growing correctly \n",
    "items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_brand</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_upc12</th>\n",
       "      <th>item_upc14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Riceland</td>\n",
       "      <td>1</td>\n",
       "      <td>Riceland American Jazmine Rice</td>\n",
       "      <td>0.84</td>\n",
       "      <td>35200264013</td>\n",
       "      <td>35200264013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caress</td>\n",
       "      <td>2</td>\n",
       "      <td>Caress Velvet Bliss Ultra Silkening Beauty Bar...</td>\n",
       "      <td>6.44</td>\n",
       "      <td>11111065925</td>\n",
       "      <td>11111065925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Earths Best</td>\n",
       "      <td>3</td>\n",
       "      <td>Earths Best Organic Fruit Yogurt Smoothie Mixe...</td>\n",
       "      <td>2.43</td>\n",
       "      <td>23923330139</td>\n",
       "      <td>23923330139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boars Head</td>\n",
       "      <td>4</td>\n",
       "      <td>Boars Head Sliced White American Cheese - 120 Ct</td>\n",
       "      <td>3.14</td>\n",
       "      <td>208528800007</td>\n",
       "      <td>208528800007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Back To Nature</td>\n",
       "      <td>5</td>\n",
       "      <td>Back To Nature Gluten Free White Cheddar Rice ...</td>\n",
       "      <td>2.61</td>\n",
       "      <td>759283100036</td>\n",
       "      <td>759283100036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_brand  item_id                                          item_name  \\\n",
       "0        Riceland        1                     Riceland American Jazmine Rice   \n",
       "1          Caress        2  Caress Velvet Bliss Ultra Silkening Beauty Bar...   \n",
       "2     Earths Best        3  Earths Best Organic Fruit Yogurt Smoothie Mixe...   \n",
       "3      Boars Head        4   Boars Head Sliced White American Cheese - 120 Ct   \n",
       "4  Back To Nature        5  Back To Nature Gluten Free White Cheddar Rice ...   \n",
       "\n",
       "   item_price    item_upc12    item_upc14  \n",
       "0        0.84   35200264013   35200264013  \n",
       "1        6.44   11111065925   11111065925  \n",
       "2        2.43   23923330139   23923330139  \n",
       "3        3.14  208528800007  208528800007  \n",
       "4        2.61  759283100036  759283100036  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview data\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting work to function\n",
    "def get_items_data(base_url):\n",
    "    '''\n",
    "    Accepts url. Create df using data from base url \n",
    "    then retrieves data from each sequential page and combines all into one DF.\n",
    "    '''\n",
    "    # saving object retrieved from requests function being passed argument URL\n",
    "    response = requests.get(base_url)\n",
    "    \n",
    "    # saving data from .json object\n",
    "    data = response.json()\n",
    "    \n",
    "    # saving first page of items data to df\n",
    "    df = pd.DataFrame(data['payload']['items'])\n",
    "    \n",
    "    # iterating range = 1 through max page count\n",
    "    for i in range (1, data['payload']['max_page']):\n",
    "        # passing url for next page to request.get function\n",
    "        response = requests.get(base_url[:23] + data['payload']['next_page'])\n",
    "        \n",
    "        # saving data from response in .json format\n",
    "        data = response.json()\n",
    "        \n",
    "        # concating each new page's data to original df\n",
    "        df = pd.concat([df, pd.DataFrame(data['payload']['items'])]).reset_index(drop=True)\n",
    "    \n",
    "    # returning df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing function\n",
    "\n",
    "# saving url to retrieve first page of items data\n",
    "items_base_url = 'https://python.zach.lol/api/v1/items'\n",
    "\n",
    "# saving function with base url passed to it\n",
    "all_items = get_items_data(items_base_url)\n",
    "\n",
    "# checking shape to ensure all data gathered\n",
    "all_items.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the same thing, but for stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_page: 1\n",
      "next_page: None\n"
     ]
    }
   ],
   "source": [
    "# variable holds python object that represents an HTTP response from the given url\n",
    "response = requests.get('https://python.zach.lol/api/v1/stores')\n",
    "\n",
    "# saving data from response in .json format\n",
    "data = response.json()\n",
    "\n",
    "# creating df from stores data\n",
    "stores = pd.DataFrame(data['payload']['stores'])\n",
    "\n",
    "# checking max page and next page\n",
    "# surprisingly, theres only one page\n",
    "print('max_page: %s' % data['payload']['max_page'])\n",
    "print('next_page: %s' % data['payload']['next_page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_address</th>\n",
       "      <th>store_city</th>\n",
       "      <th>store_id</th>\n",
       "      <th>store_state</th>\n",
       "      <th>store_zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12125 Alamo Ranch Pkwy</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>78253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9255 FM 471 West</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>2</td>\n",
       "      <td>TX</td>\n",
       "      <td>78251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2118 Fredericksburg Rdj</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>3</td>\n",
       "      <td>TX</td>\n",
       "      <td>78201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>516 S Flores St</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>4</td>\n",
       "      <td>TX</td>\n",
       "      <td>78204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1520 Austin Hwy</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>5</td>\n",
       "      <td>TX</td>\n",
       "      <td>78218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             store_address   store_city  store_id store_state store_zipcode\n",
       "0   12125 Alamo Ranch Pkwy  San Antonio         1          TX         78253\n",
       "1         9255 FM 471 West  San Antonio         2          TX         78251\n",
       "2  2118 Fredericksburg Rdj  San Antonio         3          TX         78201\n",
       "3          516 S Flores St  San Antonio         4          TX         78204\n",
       "4          1520 Austin Hwy  San Antonio         5          TX         78218"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# previewing data\n",
    "stores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking column and row count\n",
    "stores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting work to function\n",
    "def get_stores_data(base_url):\n",
    "    '''\n",
    "    Accepts url. Create df using data from base url \n",
    "    then retrieves data from each sequential page and combines all into one DF.\n",
    "    '''\n",
    "    # saving object retrieved from requests function being passed argument URL\n",
    "    response = requests.get(base_url)\n",
    "    \n",
    "    # saving data from .json object\n",
    "    data = response.json()\n",
    "    \n",
    "    # saving first page of stores data to df\n",
    "    df = pd.DataFrame(data['payload']['stores'])\n",
    "    \n",
    "    # iterating range = 1 through max page count\n",
    "    for i in range (1, data['payload']['max_page']):\n",
    "        # passing url for next page to request.get function\n",
    "        response = requests.get(base_url[:23] + data['payload']['next_page'])\n",
    "        \n",
    "        # saving data from response in .json format\n",
    "        data = response.json()\n",
    "        \n",
    "        # concating each new page's data to original df\n",
    "        df = pd.concat([df, pd.DataFrame(data['payload']['stores'])]).reset_index(drop=True)\n",
    "    \n",
    "    # returning df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing function\n",
    "\n",
    "# saving url to retrieve first page of stores data\n",
    "stores_base_url = 'https://python.zach.lol/api/v1/stores'\n",
    "\n",
    "# saving function with base url passed to it\n",
    "all_stores = get_stores_data(stores_base_url)\n",
    "\n",
    "# checking shape to ensure all data gathered\n",
    "all_stores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the data for sales. There are a lot of pages of data here, so your code will need to be a little more complex. Your code should continue fetching data from the next page until all of the data is extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting work to function\n",
    "def get_sales_data(base_url):\n",
    "    '''\n",
    "    Accepts url. Create df using data from base url \n",
    "    then retrieves data from each sequential page and combines all into one DF.\n",
    "    '''\n",
    "    # saving object retrieved from requests function being passed argument URL\n",
    "    response = requests.get(base_url)\n",
    "    \n",
    "    # saving data from .json object\n",
    "    data = response.json()\n",
    "    \n",
    "    # saving first page of sales data to df\n",
    "    df = pd.DataFrame(data['payload']['sales'])\n",
    "    \n",
    "    # iterating range = 1 through max page count\n",
    "    for i in range (1, data['payload']['max_page']):\n",
    "        # passing url for next page to request.get function\n",
    "        response = requests.get(base_url[:23] + data['payload']['next_page'])\n",
    "        \n",
    "        # saving data from response in .json format\n",
    "        data = response.json()\n",
    "        \n",
    "        # concating each new page's data to original df\n",
    "        df = pd.concat([df, pd.DataFrame(data['payload']['sales'])]).reset_index(drop=True)\n",
    "    \n",
    "    # returning df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>sale_date</th>\n",
       "      <th>sale_id</th>\n",
       "      <th>store</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Tue, 01 Jan 2013 00:00:00 GMT</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Wed, 02 Jan 2013 00:00:00 GMT</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Thu, 03 Jan 2013 00:00:00 GMT</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Fri, 04 Jan 2013 00:00:00 GMT</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Sat, 05 Jan 2013 00:00:00 GMT</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item  sale_amount                      sale_date  sale_id  store\n",
       "0     1         13.0  Tue, 01 Jan 2013 00:00:00 GMT        1      1\n",
       "1     1         11.0  Wed, 02 Jan 2013 00:00:00 GMT        2      1\n",
       "2     1         14.0  Thu, 03 Jan 2013 00:00:00 GMT        3      1\n",
       "3     1         13.0  Fri, 04 Jan 2013 00:00:00 GMT        4      1\n",
       "4     1         10.0  Sat, 05 Jan 2013 00:00:00 GMT        5      1"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing function\n",
    "\n",
    "# saving url to retrieve first page of sales data\n",
    "sales_base_url = 'https://python.zach.lol/api/v1/sales'\n",
    "\n",
    "# saving df produced from function to variable\n",
    "sales = get_sales_data(sales_base_url)\n",
    "\n",
    "# previewing data\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(913000, 5)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking shape to see how many rows/columns are in df\n",
    "sales.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data in your files to local csv files so that it will be faster to access in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving data to file sales.csv\n",
    "items.to_csv('items.csv', index=False)\n",
    "stores.to_csv('stores.csv', index=False)\n",
    "sales.to_csv('sales.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to function\n",
    "\n",
    "# function converts DFs to csv files\n",
    "def csv_maker(items, stores, sales):\n",
    "    \"\"\"\n",
    "    Accepts 3 DFs. Converts passed DFs to csv files then returns DFs.\n",
    "    \"\"\"\n",
    "    # converting DFs\n",
    "    items.to_csv('items.csv', index=False)\n",
    "    stores.to_csv('stores.csv', index=False)\n",
    "    sales.to_csv('sales.csv', index=False)\n",
    "\n",
    "    # returning DFs\n",
    "    return items, stores, sales\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the data from your three separate dataframes into one large dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(913000, 10)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating new df, complete_df, that will hold all 3 DFs\n",
    "\n",
    "# merging sales and stores DFs by matching store (sales) and store_id (stores)\n",
    "complete_df = sales.merge(stores, left_on='store', right_on='store_id')\n",
    "\n",
    "# checking column count to make sure merge was a success\n",
    "# both source DFs had 5 columns so combined they should have 10\n",
    "complete_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(913000, 16)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding items DF to complete_df by matching item (complete_df) with item_id (items)\n",
    "complete_df = complete_df.merge(items, left_on='item', right_on='item_id')\n",
    "\n",
    "# checking column count to make sure merge was a success\n",
    "# complete df had 10 columns while items df had 6 columns so new df should have 16\n",
    "complete_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to function\n",
    "\n",
    "# function combines 3 DFs from exercise\n",
    "def df_combiner(sales, stores, items):\n",
    "    \"\"\"\n",
    "    Combines 3 DFs into 1 DF.\n",
    "    \"\"\"\n",
    "    \n",
    "    # merging sales and stores DFs by matching store (sales) and store_id (stores)\n",
    "    complete_df = sales.merge(stores, left_on='store', right_on='store_id')\n",
    "    \n",
    "    # adding items DF to complete_df by matching item (complete_df) with item_id (items)\n",
    "    complete_df = complete_df.merge(items, left_on='item', right_on='item_id')\n",
    "    \n",
    "    return complete_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquire the Open Power Systems Data for Germany, which has been rapidly expanding its renewable energy production in recent years. The data set includes country-wide totals of electricity consumption, wind power production, and solar power production for 2006-2017. You can get the data here: https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Consumption</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Solar</th>\n",
       "      <th>Wind+Solar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>1069.184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-02</td>\n",
       "      <td>1380.521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>1442.533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-04</td>\n",
       "      <td>1457.217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-05</td>\n",
       "      <td>1477.131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Consumption  Wind  Solar  Wind+Solar\n",
       "0  2006-01-01     1069.184   NaN    NaN         NaN\n",
       "1  2006-01-02     1380.521   NaN    NaN         NaN\n",
       "2  2006-01-03     1442.533   NaN    NaN         NaN\n",
       "3  2006-01-04     1457.217   NaN    NaN         NaN\n",
       "4  2006-01-05     1477.131   NaN    NaN         NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing data from csv as dataframe\n",
    "power = pd.read_csv('https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv')\n",
    "\n",
    "# previewing data\n",
    "power.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to function\n",
    "\n",
    "# function to acquire german power systems data\n",
    "def get_power():\n",
    "    \"\"\"\n",
    "    No argument needed. Run function to acquire german power systems data.\n",
    "    \"\"\"\n",
    "    # saving data to variable\n",
    "    power = pd.read_csv('https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv')\n",
    "    # returning df\n",
    "    return power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure all the work that you have done above is reproducible. That is, you should put the code above into separate functions in the acquire.py file and be able to re-run the functions and get the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All solution converted to functions and added to acquire.py file\n"
     ]
    }
   ],
   "source": [
    "print('All solution converted to functions and added to acquire.py file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
